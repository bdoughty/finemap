{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSC5bcAL8vYK"
   },
   "source": [
    "# FINEMAP: efficient variable selection using summary data from genome-wide association studies \n",
    "\n",
    "*Based on work done by Benjamin Doughty, Madeleine Duran, and Sarah Walker for AM207 at Harvard, Spring 2018*\n",
    "\n",
    "Refs:\n",
    "\n",
    "[1] https://www.ncbi.nlm.nih.gov/pubmed/26773131\n",
    "\n",
    "[2] https://www.tandfonline.com/doi/abs/10.1198/016214507000000121\n",
    "\n",
    "[3] https://arxiv.org/pdf/1110.6019.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fLFWKGYBPKp"
   },
   "source": [
    "## Background and non-technical introduction\n",
    "\n",
    "The goal of this paper[1] is to develop a statistical and algorithmic framework for fine-mapping causal SNPs. Genome-Wide Association Studies (GWAS) identify regions of the genome associated with a particular trait or disease, essentially by sequencing a bunch of sick people (and healthy controls) and looking for mutations (variants or single nucleotide polymorphisms, SNPs) enriched in the sick population. However, correlation structure (linkage disequilibrium, or LD) in the genome tends to obscure the signal coming from specific variants, making it more difficult to assume that a SNP associated with a disease is actually causal for that disease. The process of fine-mapping attempts to use known information to tease out causal effects from associations. This is a challenging, high-dimensional variable selection problem, and this paper introduces a Shotgun Stochastic Search algorithm[2] to perform the fine-mapping efficiently using only GWAS summary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant methods and math\n",
    "\n",
    "The paper introduces a Bayesian hierachical framework for modeling the effects of SNPs in LD with each other, of which only a few are causal. Other papers adopt similar models (solving them using MCMC approaches, variational approximations, and EM-algorithms), yet the key insight of this paper is applying a Shotgun Stochastic Search (SSS)[2] algorithm, which allows for quick identification and efficient exploration of regions of the target space with high contributions to the posterior. Additionally, this paper only uses summary data from GWAS, which means it will scale as the studies get larger and larger. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math / model \n",
    "\n",
    "#### General linear model: \n",
    "\n",
    "Using a standard multiple linear regression formulation, the model is:\n",
    "\n",
    "$$y = X\\lambda + \\epsilon$$\n",
    "\n",
    "where $y$ is a mean-centered vector of values of a quantitative trait for $n$ individuals (the actual measured data from the GWAS), $X$ a column-standardized SNP-genotype matrix (what individuals have which SNPs) of dimension $n$ x $m$ ($m$ is number of SNPs), and $p(\\epsilon) = N(\\epsilon \\vert 0, \\sigma^2I_n) $.\n",
    "\n",
    "Interestingly, the MLE of the causal SNP effects $\\lambda$ (how strongly each SNP affects the trait under consideration) depends on $X$ and $y$ only through the SNP correlation matrix, $R = n^{-1}X^TX$ (LD matrix), and single SNP z-scores, $\\hat{z} = (n\\sigma^2)^{-1/2}X^Ty$, both of which are summary statistics commonly reported instead of the original data. \n",
    "\n",
    "$$\\hat{\\lambda} = (X^TX)^{-1}X^Ty=n^{-1/2}\\sigma R^{-1}\\hat{z}$$\n",
    "\n",
    "However, the MLE doesn't account for the sparsity of the data, which is why a Bayesian approach is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Priors: \n",
    "\n",
    "The authors let $\\gamma$ be a binary indicator vector (of length $m$) which determines which SNPs have non-zero casual effects. This will be the important quantity, and what we will find the posterior for. $\\gamma_l = 1$ if the $l$th SNP is causal and 0 otherwise.\n",
    "\n",
    "To introduce sparsity, the following prior was used for $\\lambda$:\n",
    "\n",
    "$$ p(\\lambda \\vert \\gamma) = N(\\lambda \\vert 0, s^{2}_\\lambda \\sigma^2 \\Delta_\\gamma) $$\n",
    "\n",
    "where $s_\\lambda^2$ is the user given prior variance for the casual effects in units of $\\sigma^2$ (for quantative traits, $s_\\lambda^2 = 0.05^2 $), $\\sigma^2= 1$ for quantative traits, and $\\Delta_\\gamma$ is a diagonal matrix with $\\gamma$ on the diagonal; \n",
    "\n",
    "A general discrete distribution defines the prior for the total number of causal SNPs: \n",
    "\n",
    "$p_k = \\Pr(\\text{num. of causal SNPs is }k)$, where $k=1,\\dots,K$ and $K << m$ is the maximum number of SNPs in the causal configuration. The region to be fine-mapped is assumed to include at least one causal SNP, i.e. $p_0=0$. For a fixed value of k, the same probability for each configuration with $k$ causal SNPs is assumed. \n",
    "\n",
    "$$ p(\\gamma) = p_k \\Big/ {m\\choose k}  $$ \n",
    "\n",
    "when $\\sum_{l=1}^m \\gamma_l = k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood:\n",
    "\n",
    "Before getting the posterior for $\\gamma$, we first need to calculate the likelihood $p(y \\vert \\gamma, X)$. From above, we know that the likelihood $p(y) \\sim N(\\text{_}, \\text{_})$, which is proportional to a normal density on $\\hat{\\lambda} \\sim N(\\lambda, \\sigma^2(nR)^{-1})$, which means that an analytic solution for the marginal $p(y \\vert \\gamma, X)$ can be achieved by integrating out $\\lambda$ and simplifying:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(y \\vert \\gamma, X) &= \\int p(y \\vert \\lambda, X) p(\\lambda \\vert \\gamma) d\\lambda \\\\\n",
    "&= N(\\hat{\\lambda} \\vert 0, \\sigma^2 (nR)^{-1} + s_{\\lambda}^2 \\sigma^2 \\Delta_{\\gamma}) \\\\\n",
    "&= N(\\hat{z} \\vert 0, R + R \\Sigma_{\\gamma} R)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\Sigma_{\\gamma} = ns^2_{\\lambda}\\Delta_{\\gamma}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior for $\\gamma$: \n",
    "\n",
    "Using Bayes' Rule, the unnormalized posterior can be evaluated by combining the prior with the marginal likelihood: \n",
    "\n",
    "$$p^*(\\gamma \\vert y,X) = {m\\choose k}^{-1}p_k \\times p(y \\vert \\gamma, X) $$\n",
    "\n",
    "Ideally, $p^*(\\gamma \\vert y, X)$ were normalized over all $\\sum_{k=1}^{K}{m\\choose k}$, however this is computationally intractable for modest $K$, but it turns out that almost all the posterior mass is contained in the sampled points in the SSS algorithm (below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficient Search Algorithm (Shotgun Stochastic Search): \n",
    "\n",
    "Unlike MCMC, which only considers one possible neighboring state when exploring the posterior (and is therefore often slow to explore highly-multidimensional spaces), SSS generates a whole set of neighboring configurations at each iteration and stores them for future use. This way, a large number of parameter configurations with high posterior probability are quickly explored (and stored). SSS conducts a pre-defined number of iterations within the space of causal configurations, and by the end, the set of configurations it has seen approximates the typical set. \n",
    "\n",
    "The procedure is as follows:\n",
    "\n",
    "For $1 < k < K$, the number of causal configurations to be evaluated for each iteration is: \n",
    "\n",
    "* k for deleting\n",
    "* k(m-k) for changing\n",
    "* m-k for adding a causal SNP\n",
    "\n",
    "In each iteration, the neighborhood of the current causal configuration is defined by configurations that result from deleting, changing or adding a causal SNP from the current configuration. The next iteration starts by sampling a new causal configuration from the neighborhood based on the scores (posterior probabilities of the configurations) normalized within the neighborhood. The unnormalized posterior probabilities remain fixed throughout the algorithm and can thus be memoized to avoid recomputation when already-evaluated configurations appear in another neighborhood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shfiMthzD1qx"
   },
   "source": [
    "#### Analysis and interpretation\n",
    "\n",
    "The posterior probability that SNPs in configuaration $\\gamma$ are causal is computed by normalizing over $\\Gamma^*$, where $\\Gamma^*$ stores the unnormalized posterior probabilities for all evaluated causual configurations. Ideally, $\\Gamma^*$ contains the entire typical set of configurations (those with high contributions to the posterior).\n",
    "\n",
    "$$ p(\\gamma|y,X) = p^*(\\gamma|y,X) \\Big/ \\sum_{\\gamma \\in \\Gamma^*} p^*(\\gamma|y,X)$$\n",
    "\n",
    "We can also calculate a \"single-SNP inclusion probability\", i.e. the probability that the $l$th SNP is causal. This is also known as the fine-mapped posterior probability for a SNP. \n",
    "\n",
    "$$ p(\\gamma_l = 1 | y,X) = \\mathbb{E}_{p(\\gamma \\vert y, X)} \\left [ \\gamma_l \\right ] = \\sum_{\\gamma \\in \\Gamma^*} \\mathbb{1}(\\gamma_l=1)p(\\gamma|y,X)$$\n",
    "\n",
    "We can also calculate per-SNP Bayes Factors for assessing the evidence that the $l$th SNP is causal:\n",
    "\n",
    "$$ BF(\\gamma_l = 1: \\gamma_l = 0) = \\cfrac{p(\\gamma_l=1|y, X)}{p(\\gamma_l=0|y,X)} \\Big/ \\cfrac{p(\\gamma_l=1)}{p(\\gamma_l=0)}$$\n",
    "\n",
    "Where the prior probability of the $l$th SNP being causal is: \n",
    "\n",
    "$$ p(\\gamma_l = 1) = \\sum_{k=1} {m \\choose k} p_k$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Data sets: two test data sets from the author of this paper's website (region 1 and region 2). Using genotype data with 50 SNPs and 5363 individuals, a quantative phenotype was simulated by a linear model with 2 causal SNPs. Single-SNP testing was performed to obtain z-scores. SNP correlations wre computed from individual-level genotype data. \n",
    "\n",
    "We will be comparing our implementation to FINEMAP's results, as well as our implementation of a MCMC algorithm. \n",
    "\n",
    "FINEMAP outputs the posterior probabilities for the number of causal SNPs and the evidence on $log_{10}$ scale of at least one causal SNP in a genomic region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LpF2R_PCL27N"
   },
   "source": [
    "### Our Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.misc import comb\n",
    "from matplotlib import pyplot as plt\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4Hv3Q2YyGKk6"
   },
   "outputs": [],
   "source": [
    "# initialize stuff so functions can access them\n",
    "\n",
    "gamma_neighbors = {} # string --> list of string neighbors\n",
    "gamma_posteriors = {} # string --> float\n",
    "K = 3 # max number of SNPs\n",
    "m = -1 # will be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "82XY4YTNGQoz"
   },
   "outputs": [],
   "source": [
    "s_sq = 0.05 ** 2 # prior variance for causal effect (in units of sigma^2)\n",
    "sigma_sq = 1 ** 2 # can assume sigma^2 = 1 w/o loss of generality\n",
    "n = 5363 # number of people in the sample from the datas file\n",
    "\n",
    "# can speed this up with results from their paper, but don't have to\n",
    "def likelihood(gamma, R, z):\n",
    "    # construct sigma matrix from gamma\n",
    "    Sigma = np.diag(np.fromiter(map(int, gamma), dtype=np.int) * s_sq * sigma_sq * n)\n",
    "    cov = R + R @ Sigma @ R\n",
    "    # evaluate likelihood at point z\n",
    "    p = multivariate_normal.pdf(z, mean=None, cov=cov, allow_singular=True)\n",
    "    # can also play around with log-likelihood, if needed for numerical stability\n",
    "    # lp = multivariate_normal.logpdf(z, mean=None, cov=cov, allow_singular=True)\n",
    "    return p\n",
    "\n",
    "# prior probability of lth SNP being causal (this is constant)\n",
    "def prior_causal_SNP(p_k):\n",
    "    return sum([p_k[0,k-1] * k/m for k in range(1,K+1)])\n",
    "\n",
    "# calculate bayes factor for SNPs, given a pp\n",
    "def bayes_factor(snp_inc_prob, p_k):\n",
    "    pcs = prior_causal_SNP(p_k)\n",
    "    return snp_inc_prob / (1 - snp_inc_prob) / (pcs / (1 - pcs))\n",
    "\n",
    "# calculate the marginal posterior for SNPs\n",
    "# p(SNP_i included in causal configuration)\n",
    "def SNP_inclusion_prob():\n",
    "    # first normalize posterior\n",
    "    total_post = sum([pr for (pr, count) in gamma_posteriors.values()]) # sum([pr*count for (pr, count) in gamma_posteriors.values()])\n",
    "\n",
    "    # then marginalize posterior for each SNP\n",
    "    acc = np.zeros(m)\n",
    "    for g in gamma_posteriors:\n",
    "        pr, count = gamma_posteriors[g]\n",
    "        g_array = np.fromiter(map(int, g), dtype=np.int)\n",
    "        acc +=  g_array * pr / total_post # g_array * pr * count / total_post\n",
    "    return acc\n",
    "\n",
    "# compute the posterior for a given causal configuration\n",
    "def posterior(gamma, R, z, p_k):\n",
    "    k = gamma.count('1') # num causals SNPs\n",
    "    m = len(gamma) # num SNPs\n",
    "    mCk = comb(m, k)\n",
    "    if (k <= len(p_k[0])) and (k > 0):\n",
    "        # compute p(gamma | X, y) ~ p(y | X, gamma) p(gamma)\n",
    "        posterior = p_k[0][k-1] / mCk * likelihood(gamma, R, z)\n",
    "        return posterior\n",
    "    else:\n",
    "        # we set the pp to 0 if k = 0 or if there are more causal than threshold\n",
    "        return 0\n",
    "\n",
    "# run shotgun stochastic search\n",
    "def SSS(R, z, p_k, n_iter=1000):\n",
    "    # initialize a starting guess\n",
    "    k_init = np.random.randint(len(p_k[0])) + 1\n",
    "    gamma = np.zeros(m)\n",
    "    for i in range(k_init):\n",
    "        gamma[i] = 1\n",
    "    gamma = ''.join(map(str, map(int, np.random.permutation(gamma))))\n",
    "    # run the algorithm for a given number of iterations\n",
    "    for _ in range(n_iter):\n",
    "        gamma = SSS_step(gamma, R, z, p_k)\n",
    "\n",
    "# run one iteration of SSS, generate neighborhood and evaluate the posterior\n",
    "# at each, then choose from the neighborhood\n",
    "def SSS_step(gamma, R, z, p_k):\n",
    "    # get all neighbors of given causal configuration gamma\n",
    "    neighbors = generate_neighbors(gamma)\n",
    "    post_prob = []\n",
    "    # get posterior probabilities for each of the neighbors\n",
    "    for neighbor in neighbors:\n",
    "        if not neighbor in gamma_posteriors:\n",
    "            gamma_posteriors[neighbor] = posterior(neighbor, R, z, p_k), 0\n",
    "        else:\n",
    "            post, count = gamma_posteriors[neighbor]\n",
    "            gamma_posteriors[neighbor] = post, count+1\n",
    "        post_prob.append(gamma_posteriors[neighbor][0])\n",
    "    # sample from the posterior probabilities to retun one neighbor\n",
    "    return np.random.choice(neighbors, size=1, p=post_prob/np.sum(post_prob))\n",
    "\n",
    "# find all neighbors that are one insertion, deletion, or swap away\n",
    "def generate_neighbors(gamma_array):\n",
    "    gamma = \"\".join(gamma_array)\n",
    "    if not gamma in gamma_neighbors:\n",
    "        # generate all strings 1 away from gamma\n",
    "        ns = [] \n",
    "        for i, x in enumerate(gamma):\n",
    "            ## add SNP at i if x is 0\n",
    "            ## delete SNP at i if x is 1\n",
    "            switched = \"1\" if x==\"0\" else \"0\"\n",
    "            ns.append(gamma[0:i]+ switched+gamma[i+1:])\n",
    "            # if x is 1, switch it with each 0 after it\n",
    "            # if x is 0, switch it with each 1 after it\n",
    "            for j, y in enumerate(gamma[i+1:]):\n",
    "                if y != x:\n",
    "                      ns.append(gamma[0:i] + y + gamma[i+1:i+j+1] + x + gamma[i+j+2:])\n",
    "        gamma_neighbors[gamma] = ns\n",
    "    return gamma_neighbors[gamma]\n",
    "\n",
    "\n",
    "## test generate neighbors\n",
    "assert set(generate_neighbors(\"101\")) == set([\"001\", \"100\", \"011\", \"110\", \"111\"])\n",
    "assert set(generate_neighbors(\"011\")) == set([\"001\", \"010\", \"101\", \"110\", \"111\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28659,
     "status": "ok",
     "timestamp": 1524515750695,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "AwhF2Bl0IDJN",
    "outputId": "5fc10460-a319-4c60-bb6f-f17e23392722"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'region1.ld' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-26f43fa3b2a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrue_snp_ex1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msip_ex1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_ex1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region1.ld\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region1.z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region1.k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region1.snp\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"Example Region 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mtrue_snp_ex2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msip_ex2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_ex2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region2.ld\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region2.z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region2.k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region2.snp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Example Region 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-26f43fa3b2a5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(ld_file, z_file, k_file, snps_file, title, n_iter)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mld_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnps_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mld_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'region1.ld' does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "def run(ld_file, z_file, k_file, snps_file, title, n_iter=10000):\n",
    "\n",
    "    ld = np.asmatrix(pd.read_csv(ld_file, delim_whitespace=True, header=None))\n",
    "    z = pd.read_csv(z_file, delim_whitespace=True, header=None).as_matrix()\n",
    "    k = pd.read_csv(k_file, delim_whitespace=True, header=None).as_matrix()\n",
    "\n",
    "    global gamma_neighbors, gamma_posteriors, K, m \n",
    "    gamma_neighbors = {} # string --> list of string neighbors\n",
    "    gamma_posteriors = {} # string --> float, count\n",
    "\n",
    "    K=k.shape[1] # max number of SNPs\n",
    "    m = len(z)\n",
    "\n",
    "    SSS(R=ld, z=z[:,1], p_k=k, n_iter=n_iter)\n",
    "\n",
    "    sip = SNP_inclusion_prob()\n",
    "    bf = bayes_factor(sip, k)\n",
    "\n",
    "    true_snps = pd.read_csv(snps_file, sep=\" \")\n",
    "    true_snps[\"our_prob\"] = [sip[i-1] for i in true_snps[\"index\"]]\n",
    "\n",
    "    plt.scatter(true_snps['snp_prob'], true_snps['our_prob'])\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlim(1e-3, 2)\n",
    "    plt.ylim(1e-3, 2)\n",
    "    plt.plot([0,1], linewidth=0.2, color=\"purple\")\n",
    "    plt.xlabel(\"FINEMAP implementation\")\n",
    "    plt.ylabel(\"our implementation\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return true_snps, sip, bf\n",
    "\n",
    "\n",
    "true_snp_ex1, sip_ex1, bayes_ex1 = run(\"region1.ld\", \"region1.z\", \"region1.k\", \"region1.snp\" , \"Example Region 1\")\n",
    "true_snp_ex2, sip_ex2, bayes_ex2 = run(\"region2.ld\", \"region2.z\", \"region2.k\", \"region2.snp\", \"Example Region 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1779,
     "status": "ok",
     "timestamp": 1524517161204,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "40Iw5J0RPk5A",
    "outputId": "89bd5eb4-f605-413f-dc14-1980b7b24fef"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_snp_ex1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c45852c6b9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here we compare our ordering to those from FINEMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtheir_snp_ordering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_snp_ex1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"snp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mour_snp_ordering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_snp_ex1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"our_prob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_snp_ex1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"snp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_snp_ex1' is not defined"
     ]
    }
   ],
   "source": [
    "# here we compare our ordering to those from FINEMAP\n",
    "\n",
    "their_snp_ordering = np.array(true_snp_ex1[\"snp\"])\n",
    "our_snp_ordering = [x for _,x in sorted(zip(true_snp_ex1[\"our_prob\"], true_snp_ex1[\"snp\"]), reverse=True)]\n",
    "\n",
    "def get_within_x(theirs, ours, x=1):\n",
    "    count = 0\n",
    "  \n",
    "    for i,snp in enumerate(ours):\n",
    "        for diff in range(x+1):\n",
    "            if i-diff >=0 and i+diff < len(theirs):\n",
    "                if snp == theirs[i-diff] or snp == theirs[i+diff]:\n",
    "                    count += 1\n",
    "                    break\n",
    "    return count\n",
    "\n",
    "print(get_within_x(their_snp_ordering, our_snp_ordering, 0)) # should be 14\n",
    "print(get_within_x(their_snp_ordering, our_snp_ordering, 1)) # 33 snps are within 1 place different\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxHku5UpOVCY"
   },
   "source": [
    "#### How Our Results Compare to FINEMAP\n",
    "\n",
    "Our results aren't perfect (especially for the really small probabilities), but we are quite close to the FINEMAP implementation overall and observe a strong linear correlation between our results. Additionally, this analysis runs quite quickly, even without the modifications meant to speed up the evaluation of the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_OA0FD-TI5N"
   },
   "source": [
    "\n",
    "### MCMC Implementation \n",
    "\n",
    "We now implement a MCMC algorithm. Our model is based on the one found in the following paper:  Bayesian Variable Selection Regression for Genome-Wide Association Studies and Other Large-Scale Problems [https://arxiv.org/pdf/1110.6019.pdf]. They frame the problem as a Bayesian Variable Selection Regressions where SNPs are the covariates in the regression. \n",
    "\n",
    "\n",
    "#### Model: \n",
    "$\\pi$ controls the sparsity of the model. In GWAS, there could be a few relevant covariates or hundreds. A uniform prior on $\\pi$ seems inappropriate, so instead, they put a uniform prior on $\\log\\pi$: \n",
    "\n",
    "$ \\log(\\pi) \\sim U(a,b) $\n",
    "\n",
    "where $ a = log(1/p)$ and $b = log(M/p)$, $M$ is the maximum number of $p$ SNPs we think might be causal\n",
    "\n",
    "$\\gamma$ is a vector of binary indicators that indicate which elements of $\\beta$ are nonzero. It is reasonable to interpret $\\gamma_j = 1$ as indicating that SNP $j$, has a causal affect on y, the measured response variable. \n",
    "\n",
    "$ \\gamma_j \\sim Bernoulli(\\pi)$ \n",
    "\n",
    "We then use this $\\gamma$ in the model defined previously. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HrNa--tKNBLQ"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    with mcmcModel:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "\n",
    "s_sq = 0.05 ** 2 # prior variance for causal effect (in units of sigma^2)\n",
    "sigma_sq = 1 ** 2 # can assume sigma^2 = 1 w/o loss of generality\n",
    "n = 5363 # number of people in the sample from the datas file\n",
    "\n",
    "# now do normal MCMC\n",
    "def generate_mcmc_trace(ld_file, z_file, num_samples=1000):\n",
    "    R = np.asmatrix(pd.read_csv(ld_file, delim_whitespace=True, header=None))\n",
    "    z = pd.read_csv(z_file, delim_whitespace=True, header=None).as_matrix()[:,1]\n",
    "  \n",
    "    with pm.Model() as mcmcModel:\n",
    "        logpi = pm.Uniform('logpi', np.log(1 / 50), np.log(50 / 50))\n",
    "        gamma = pm.Bernoulli('gamma', p=np.exp(logpi), shape=50)\n",
    "\n",
    "        Delta = T.nlinalg.diag(gamma)\n",
    "        Sigma = Delta * s_sq * sigma_sq * n\n",
    "        S = theano.shared(R)\n",
    "        cov = S + T.dot(S, T.dot(Sigma, S))\n",
    "\n",
    "        p = pm.MvNormal('p', mu=0, cov=cov, observed=z)\n",
    "  \n",
    "      with mcmcModel:\n",
    "        step = pm.NUTS()\n",
    "        trace = pm.sample(num_samples, step=step)\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209464,
     "status": "ok",
     "timestamp": 1524519741165,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "9hhVQxb_ab1y",
    "outputId": "8902cb0d-c393-4913-b6b9-9f88886427fb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_mcmc_trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c1560c84b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_mcmc_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region1.ld\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region1.z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_mcmc_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region2.ld\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"region2.z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_mcmc_trace' is not defined"
     ]
    }
   ],
   "source": [
    "tr1 = generate_mcmc_trace(\"region1.ld\", \"region1.z\", 1000)\n",
    "tr2 = generate_mcmc_trace(\"region2.ld\", \"region2.z\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4908,
     "status": "ok",
     "timestamp": 1524519746097,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "PE_8oS2ecADw",
    "outputId": "445ff17f-9810-46c2-9cbb-8ae5c14d4bd4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-48a7dc3db93e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr1' is not defined"
     ]
    }
   ],
   "source": [
    "pm.traceplot(tr1)\n",
    "pm.traceplot(tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1755,
     "status": "ok",
     "timestamp": 1524519885789,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "Ngl_UbsJdYGx",
    "outputId": "6c970ab7-3882-4e8e-8a8e-732b35612409"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f6e665d26b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot FINEMAP truth vs our implementation of MCMC for region 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmcmc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue_snps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region1.snp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr1' is not defined"
     ]
    }
   ],
   "source": [
    "# plot FINEMAP truth vs our implementation of MCMC for region 1\n",
    "\n",
    "mcmc_probs = tr1[\"gamma\"].mean(axis=0)\n",
    "\n",
    "true_snps = pd.read_csv(\"region1.snp\", sep=\" \")\n",
    "true_snps[\"our_prob\"] = [mcmc_probs[i-1] for i in true_snps[\"index\"]]\n",
    "\n",
    "plt.scatter(true_snps['snp_prob'], true_snps['our_prob'])\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlim(1e-3, 2)\n",
    "plt.ylim(1e-3, 2)\n",
    "plt.plot([0,1], linewidth=0.2, color=\"purple\")\n",
    "plt.xlabel(\"FINEMAP implementation\")\n",
    "plt.ylabel(\"MCMC implementation\")\n",
    "plt.title(\"Region 1 MCMC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1524520042801,
     "user": {
      "displayName": "Sarah Walker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110193930370040581263"
     },
     "user_tz": 240
    },
    "id": "lPhy-tyeeZFU",
    "outputId": "25efac85-edad-4ce1-8dcc-b33341cae324"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2564b954061c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmcmc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrue_snps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"region2.snp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr2' is not defined"
     ]
    }
   ],
   "source": [
    "# plot FINEMAP truth vs our implementation of MCMC for region 2\n",
    "\n",
    "\n",
    "mcmc_probs = tr2[\"gamma\"].mean(axis=0)\n",
    "\n",
    "true_snps = pd.read_csv(\"region2.snp\", sep=\" \")\n",
    "true_snps[\"our_prob\"] = [mcmc_probs[i-1] for i in true_snps[\"index\"]]\n",
    "\n",
    "plt.scatter(true_snps['snp_prob'], true_snps['our_prob'])\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlim(1e-3, 2)\n",
    "plt.ylim(1e-3, 2)\n",
    "plt.plot([0,1], linewidth=0.2, color=\"purple\")\n",
    "plt.xlabel(\"FINEMAP implementation\")\n",
    "plt.ylabel(\"MCMC implementation\")\n",
    "plt.title(\"Region 2 MCMC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4McCVVcbdCwZ"
   },
   "source": [
    "### MCMC vs FINEMAP\n",
    "\n",
    "MCMC does not perform as well, it is much slower and isn't good at distinguishing between lower probability options. We still see a strong linear correlation. In the paper, the authors of FINEMAP mention that their algorithm might underestimate the smaller probabilities, so the larger probabilities we get with MCMC might actually be closer to the truth. However, the MCMC still takes much longer to run (even for a few iterations) than the SSS and produces fewer samples from the posterior."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "AM207Project.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
